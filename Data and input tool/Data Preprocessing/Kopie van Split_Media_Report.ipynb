{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["1. Take original datast\n","2. Select columns\n","3. Split the dataset to have every precision event type on a seperate row"],"metadata":{"id":"iXWcXDMdjd7a"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lez5sjkBDRE4"},"outputs":[],"source":["import pandas as pd \n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"--cQ4-plDSfr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Data Science in Practice/Data and input tool/Processed Data/media_cleaned.csv')"],"metadata":{"id":"4HRNwRu2D3-i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_csv('filtered_df.csv')"],"metadata":{"id":"-UOmXnrhi_p6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Splitting rows to separate event type rows"],"metadata":{"id":"YNSYcHgE1mTG"}},{"cell_type":"code","source":["import csv\n","with open('edited_df.csv', 'w') as f:\n","    # create the csv writer\n","    writer = csv.writer(f)\n","    idx = 0\n","    with open('filtered_df.csv', 'r') as file:\n","        reader = csv.reader(file)\n","        for row in reader:\n","            if idx == 0:\n","                writer.writerow(row)\n","                idx += 1\n","                continue\n","            writer.writerow(row)\n","            if row[4] != '':\n","                new_row = row\n","                new_row[3] = row[4]\n","                writer.writerow(new_row)\n","            if row[5] != '':\n","                new_row = row\n","                new_row[3] = row[5]\n","                writer.writerow(new_row)\n","            if row[6] != '':\n","                new_row = row\n","                new_row[3] = row[6]\n","                writer.writerow(new_row)\n","\n","event_type_separated_df = pd.read_csv('edited_df.csv')\n","event_type_separated_df.drop(['Event-Type 2', 'Event-Type 3', 'Event-Type 4'], axis=1, inplace=True)\n","event_type_separated_df.to_csv('event_type_separated_df.csv')"],"metadata":{"id":"rq0htdA1lzri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('event_type_edited.csv', 'w') as f:\n","    # create the csv writer\n","    writer = csv.writer(f)\n","    idx = 0\n","    with open('event_type_separated_df.csv', 'r') as file:\n","        reader = csv.reader(file)\n","        for row in reader:\n","            writer.writerow(row)\n","            if idx == 0:\n","                idx += 1\n","                continue\n","            if row[4] == 'Health':\n","                if row[5] != '':\n","                    new_row = row\n","                    new_row[5] = row[5]\n","                    writer.writerow(new_row)\n","                if row[6] != '':\n","                    new_row = row\n","                    new_row[5] = row[6]\n","                    writer.writerow(new_row)\n","                if row[7] != '':\n","                    new_row = row\n","                    new_row[5] = row[7]\n","                    writer.writerow(new_row) \n","                if row[8] != '':\n","                    new_row = row\n","                    new_row[5] = row[8]\n","                    writer.writerow(new_row)\n","\n","            if row[4] == 'Social':\n","                if row[9] != '':\n","                    new_row = row\n","                    new_row[5] = row[9]\n","                    writer.writerow(new_row)\n","                if row[10] != '':\n","                    new_row = row\n","                    new_row[5] = row[10]\n","                    writer.writerow(new_row)\n","                if row[11] != '':\n","                    new_row = row\n","                    new_row[5] = row[11]\n","                    writer.writerow(new_row) \n","                if row[12] != '':\n","                    new_row = row\n","                    new_row[5] = row[12]\n","                    writer.writerow(new_row)\n","                if row[13] != '':\n","                    new_row = row\n","                    new_row[5] = row[13]\n","                    writer.writerow(new_row)\n","                if row[14] != '':\n","                    new_row = row\n","                    new_row[5] = row[14]\n","                    writer.writerow(new_row)\n","                if row[15] != '':\n","                    new_row = row\n","                    new_row[5] = row[15]\n","                    writer.writerow(new_row) \n","\n","            if row[4] == 'Movements':\n","                if row[16] != '':\n","                    new_row = row\n","                    new_row[5] = row[16]\n","                    writer.writerow(new_row)\n","                if row[17] != '':\n","                    new_row = row\n","                    new_row[5] = row[17]\n","                    writer.writerow(new_row)\n","                if row[18] != '':\n","                    new_row = row\n","                    new_row[5] = row[18]\n","                    writer.writerow(new_row) \n","                if row[19] != '':\n","                    new_row = row\n","                    new_row[5] = row[19]\n","                    writer.writerow(new_row)\n","                if row[20] != '':\n","                    new_row = row\n","                    new_row[5] = row[20]\n","                    writer.writerow(new_row)\n","                if row[21] != '':\n","                    new_row = row\n","                    new_row[5] = row[21]\n","                    writer.writerow(new_row)\n","                \n","\n","            if row[4] == 'Security':\n","                 if row[22] != '':\n","                     new_row = row\n","                     new_row[5] = row[22]\n","                     writer.writerow(new_row)\n","                 if row[23] != '':\n","                     new_row = row\n","                     new_row[5] = row[23]\n","                     writer.writerow(new_row)\n","                 if row[24] != '':\n","                     new_row = row\n","                     new_row[5] = row[24]\n","                     writer.writerow(new_row)\n","                 if row[25] != '':\n","                     new_row = row\n","                     new_row[5] = row[25]\n","                     writer.writerow(new_row)\n","\n","event_type_edited_df = pd.read_csv('event_type_edited.csv')\n","event_type_edited_df.drop(['Event-Type-health 2', 'Event-Type-health 3', 'Event-Type-health 4', 'Event-Type-Social 1', 'Event-Type-Social 2', 'Event-Type-Social 3',\n","                  'Event-Type-Social 4', 'Event-Type-Social 5', 'Event-Type-Social 6', 'Event-Type-Social 7', 'Event-Type-Movements 1', 'Event-Type-Movements 2', 'Event-Type-Movements 3',\n","                  'Event-Type-Movements 4', 'Event-Type-Movements 5', 'Event-Type-Movements 6', 'Event-Type Security 1', 'Event-Type Security 2', 'Event-Type Security 3', 'Event-Type Security 4'], axis=1, inplace=True)\n","event_type_edited_df.rename(columns={'Event-Type-health 1': 'Event-Type Precision'}, inplace=True)\n","event_type_edited_df.to_csv('event_type_edited.csv')"],"metadata":{"id":"Aafvk0IHmCLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('event_type_location_separated.csv', 'w') as f:\n","    # create the csv writer\n","    writer = csv.writer(f)\n","    idx = 0\n","    with open('event_type_edited.csv', 'r') as file:\n","        reader = csv.reader(file)\n","        for row in reader:\n","            writer.writerow(row)\n","            if idx == 0:\n","                idx += 1\n","                continue\n","            if row[27] != '':\n","                new_row = row\n","                new_row[18] = row[27]\n","                new_row[19] = row[28]\n","                new_row[20] = row[29]\n","                new_row[21] = row[30]\n","                new_row[22] = row[31]\n","                new_row[23] = row[32]\n","                new_row[24] = row[33]\n","                new_row[25] = row[34]\n","                new_row[26] = row[35]\n","                writer.writerow(new_row)\n","            if row[36] != '':\n","                new_row = row\n","                new_row[18] = row[36]\n","                new_row[19] = row[37]\n","                new_row[20] = row[38]\n","                new_row[21] = row[39]\n","                new_row[22] = row[40]\n","                new_row[23] = row[41]\n","                new_row[24] = row[42]\n","                new_row[25] = row[43]\n","                new_row[26] = row[44]\n","                writer.writerow(new_row)\n","            if row[45] != '':\n","                new_row[18] = row[45]\n","                new_row[19] = row[46]\n","                new_row[20] = row[47]\n","                new_row[21] = row[48]\n","                new_row[22] = row[49]\n","                new_row[23] = row[50]\n","                new_row[24] = row[51]\n","                new_row[25] = row[52]\n","                new_row[26] = row[53]\n","                writer.writerow(new_row)\n","event_type_location_separated_df = pd.read_csv('event_type_location_separated.csv')\n","event_type_location_separated_df.drop(['City 2', 'Latitude-city 2_degrees', \n","                  'Latitude-city 2_minutes', 'Latitude-city 2_seconds', 'Latitude-city 2_direction', 'Longitude-city 2_degrees', 'Longitude-city 2_minutes', 'Longitude-city 2_seconds', 'Longitude-city 2_direction',\n","                  'City 3', 'Latitude-City 3_degrees', 'Latitude-City 3_minutes', 'Latitude-City 3_seconds','Latitude-City 3_direction', 'Longitude-City 3_degrees', 'Longitude-City 3_minutes', \n","                  'Longitude-City 3_seconds', 'Longitude-City 3_direction', 'City 4', 'Latitude-City 4_degrees', 'Latitude-City 4_minutes', 'Latitude-City 4_seconds',\n","                  'Latitude-City 4_direction', 'Longitude-City 4_degrees', 'Longitude-City 4_minutes', 'Longitude-City 4_seconds', 'Longitude-City 4_direction'], axis=1, inplace=True)\n"],"metadata":{"id":"NIhWEUULvejp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["event_type_location_separated_df = event_type_location_separated_df.rename(columns={'Unnamed: 0.1.1': 'Article ID', 'Event Date 1': 'Event Date', 'Event-Type 1': 'Event Type'}).drop(['Unnamed: 0.1', 'Unnamed: 0', 'Event Date 2'], axis=1)"],"metadata":{"id":"9za7vTFglurh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print number of unique values\n","event_type_location_separated_df.drop_duplicates(inplace=True)\n","print(event_type_location_separated_df.nunique())\n","print('')\n","print(event_type_location_separated_df.isna().sum())"],"metadata":{"id":"oZKY_fTIxDpP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["event_type_location_separated_df.to_csv('/content/drive/MyDrive/Data Science in Practice/Data and input tool/Processed Data/media_reports_processed.csv')"],"metadata":{"id":"xQpuEZGdMcqk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Drop row that has all NaN values\n","df2=filtered_df.dropna(how='all').reset_index(drop=True)"],"metadata":{"id":"ZILtWZzMU5Uh"},"execution_count":null,"outputs":[]}]}